{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.2 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:53:06) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "print(sys.version)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MF_RS():\n",
    "    def __init__(self, numUsers, numSongs, embedding_dim, reg_lambda=0.01, conf_lambda=1.0):\n",
    "        \n",
    "        #hyper parameters\n",
    "        self.batch_size = np.min([200, numUsers, numSongs]);\n",
    "        self.numUsers = numUsers\n",
    "        self.numSongs = numSongs\n",
    "        self.epochs = 50\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.conf_lambda = conf_lambda\n",
    "        \n",
    "        #embedding matricies for users and songs\n",
    "        self.userMat = tf.Variable(tf.random_normal([numUsers, embedding_dim]))\n",
    "        self.songMat = tf.Variable(tf.random_normal([numSongs, embedding_dim]))\n",
    "        self.userBias = tf.Variable(tf.random_normal([numUsers]))\n",
    "        self.songBias = tf.Variable(tf.random_normal([numSongs]))\n",
    "        self.overallBias = tf.Variable(tf.random_normal([1]))\n",
    "        self.C_user = tf.Variable(.1*tf.ones([numUsers]))\n",
    "        self.C_song = tf.Variable(.1*tf.ones([numSongs]))\n",
    "        \n",
    "        #input tensors for songs, usres, ratings\n",
    "        self.users = tf.placeholder(tf.int32, shape =(self.batch_size))\n",
    "        self.songs = tf.placeholder(tf.int32, shape =(self.batch_size))\n",
    "        self.rating = tf.placeholder(tf.float32, shape = (self.batch_size))\n",
    "        \n",
    "        #map each user/song to its feature vector\n",
    "        self.U = tf.nn.embedding_lookup(self.userMat, self.users)\n",
    "        self.W = tf.nn.embedding_lookup(self.songMat, self.songs)\n",
    "        # bias\n",
    "        self.U_bias = tf.nn.embedding_lookup(self.userBias, self.users)\n",
    "        self.W_bias = tf.nn.embedding_lookup(self.songBias, self.songs)\n",
    "        # confidence params\n",
    "        self.C_ui = tf.maximum(0.0, tf.nn.embedding_lookup(self.C_user, self.users))\n",
    "        self.C_sj = tf.maximum(0.0, tf.nn.embedding_lookup(self.C_song, self.songs))\n",
    "\n",
    "        \n",
    "        #predicted rating is dot product of user and song\n",
    "        bias = self.U_bias+self.W_bias+self.overallBias\n",
    "        pq = tf.reduce_sum(tf.mul(self.U, self.W), 1)\n",
    "        self.yhat = pq + bias\n",
    "            \n",
    "        # l2 reg\n",
    "        self.confidence_reg = self.conf_lambda * tf.reduce_sum(tf.exp(-self.C_ui) + tf.exp(-self.C_sj))\n",
    "        self.l2_reg = self.reg_lambda * ( tf.reduce_sum((tf.square(self.U) + tf.square(self.W))) + \n",
    "                                         tf.reduce_sum(tf.square(self.U_bias) + tf.square(self.W_bias)))\n",
    "        self.reg = self.confidence_reg + self.l2_reg\n",
    "        self.error = tf.reduce_mean(self.C_ui * self.C_sj * tf.nn.l2_loss(self.yhat - self.rating))\n",
    "        self.cost = (self.error + self.reg)/1e7\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate = .01).minimize(self.cost)\n",
    "        \n",
    "        self.session = tf.Session()\n",
    "        self.session.run(tf.initialize_all_variables())    \n",
    "        \n",
    "    def train(self, users, songs, ratings):\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            avg_cost = 0\n",
    "            perm = np.random.permutation(len(ratings))\n",
    "            num_batches = len(ratings) // self.batch_size\n",
    "            \n",
    "            for b_idx in range(num_batches):\n",
    "                \n",
    "                batch = perm[self.batch_size * b_idx:self.batch_size * (b_idx + 1)]\n",
    "                users_batch = users[batch]\n",
    "                songs_batch = songs[batch]\n",
    "                ratings_batch = ratings[batch]\n",
    "                                \n",
    "                avg_cost += self.session.run([self.cost, self.optimizer],\n",
    "                                  {self.users:users_batch, self.songs:songs_batch, self.rating:ratings_batch})[0]\n",
    "                \n",
    "            print(avg_cost/num_batches)\n",
    "    def test(self, users, songs):\n",
    "        yhat = np.zeros(len(users))\n",
    "        num_batches = len(users) // self.batch_size\n",
    "        for b_idx in range(num_batches):\n",
    "            batch = range(self.batch_size * b_idx,self.batch_size * (b_idx + 1))\n",
    "            users_batch = users[batch]\n",
    "            songs_batch = songs[batch]\n",
    "            yhat[batch] = self.session.run([self.yhat],\n",
    "                      {self.users:users_batch, self.songs:songs_batch})[0]\n",
    "        batch = range(-self.batch_size,0)\n",
    "        users_batch = users[batch]\n",
    "        songs_batch = songs[batch]\n",
    "        yhat[batch] = self.session.run([self.yhat],\n",
    "                      {self.users:users_batch, self.songs:songs_batch})[0]\n",
    "        return yhat\n",
    "    def evaluate(self, users, songs, ratings):\n",
    "        yhat = self.test(users, songs)\n",
    "        return np.mean((yhat - ratings)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.01680780062e-06\n",
      "1.01670809727e-06\n",
      "1.01656951301e-06\n",
      "1.01640262073e-06\n",
      "1.0162128774e-06\n",
      "1.01600369362e-06\n",
      "1.0157775705e-06\n",
      "1.01553655441e-06\n",
      "1.0152817822e-06\n",
      "1.01501450445e-06\n",
      "1.01473540326e-06\n",
      "1.01444504708e-06\n",
      "1.01414377696e-06\n",
      "1.01383193396e-06\n",
      "1.01350951809e-06\n",
      "1.01317675671e-06\n",
      "1.01283330878e-06\n",
      "1.01247940165e-06\n",
      "1.01211469428e-06\n",
      "1.01173895928e-06\n",
      "1.01135219666e-06\n",
      "1.01095406535e-06\n",
      "1.01054433799e-06\n",
      "1.01012290088e-06\n",
      "1.00968952665e-06\n",
      "1.00924387425e-06\n",
      "1.00878605735e-06\n",
      "1.00831550753e-06\n",
      "1.00783222479e-06\n",
      "1.00733620911e-06\n",
      "1.00682689208e-06\n",
      "1.00630450106e-06\n",
      "1.00576858131e-06\n",
      "1.00521913282e-06\n",
      "1.00465547348e-06\n",
      "1.00407783066e-06\n",
      "1.00348563592e-06\n",
      "1.00287866189e-06\n",
      "1.0022566812e-06\n",
      "1.00161901173e-06\n",
      "1.00096565347e-06\n",
      "1.000296038e-06\n",
      "9.99609596875e-07\n",
      "9.98905875349e-07\n",
      "9.9818430499e-07\n",
      "9.97444658424e-07\n",
      "9.96685912469e-07\n",
      "9.95907726065e-07\n",
      "9.95109530777e-07\n",
      "9.94290417111e-07\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3, 4, 5])\n",
    "b = np.array([1, 2, 3, 4, 5])\n",
    "c = np.array([4, 3, 2, 5, 1])\n",
    "#unique users / songs\n",
    "uni_a = np.unique(a)\n",
    "uni_b = np.unique(b)\n",
    "\n",
    "#dict mapping the id to an index\n",
    "a_map = dict(zip(uni_a,range(len(uni_a))))\n",
    "b_map = dict(zip(uni_b,range(len(uni_b))))\n",
    "\n",
    "user_idx =  np.array([ a_map[user] for user in a])\n",
    "song_idx =  np.array([ b_map[song] for song in b])\n",
    "model = MF_RS(len(uni_a), len(uni_b), 7)\n",
    "np.random.seed(1)\n",
    "model.train(user_idx, song_idx, c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movieratings = pd.read_csv('ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getDfSummary(input_data):\n",
    "    output_data = input_data.describe(include = 'all').T\n",
    "    var = pd.DataFrame(data = {'nanvals': pd.Series(), 'number_distinct': pd.Series()})\n",
    "    for i in range(len(input_data.columns)):\n",
    "        nanvals = input_data.ix[:,i].isnull().sum()\n",
    "        number_distinct = len(input_data.ix[:,i].value_counts())\n",
    "        var = var.append(pd.DataFrame([[nanvals, number_distinct]], columns = ['nanvals', 'number_distinct']))\n",
    "    var.index = output_data.index.values\n",
    "    output_data['nanvals'] = var['nanvals']\n",
    "    output_data['number_distinct'] = var['number_distinct']\n",
    "    return output_data\n",
    "output_data = getDfSummary(movieratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671 9066\n"
     ]
    }
   ],
   "source": [
    "users = movieratings.ix[:,0].values\n",
    "songs = movieratings.ix[:,1].values\n",
    "ratings = movieratings.ix[:,2].values\n",
    "\n",
    "#unique users / songs\n",
    "uni_users = movieratings['userId'].unique()\n",
    "uni_songs = movieratings['movieId'].unique()\n",
    "\n",
    "#dict mapping the id to an index\n",
    "user_map = dict(zip(uni_users,range(len(uni_users))))\n",
    "song_map = dict(zip(uni_songs,range(len(uni_songs))))\n",
    "\n",
    "user_idx =  np.array([ user_map[user] for user in users])\n",
    "song_idx =  np.array([ song_map[song] for song in songs])\n",
    "\n",
    "print(len(uni_users),len(uni_songs))\n",
    "\n",
    "perm = np.random.permutation(len(users))\n",
    "trn_idx = perm[:(len(users)*2)//3]\n",
    "val_idx = perm[(len(users)*2)//3:]\n",
    "user_idx_trn, song_idx_trn, ratings_trn = user_idx[trn_idx], song_idx[trn_idx], ratings[trn_idx]\n",
    "user_idx_val, song_idx_val, ratings_val = user_idx[val_idx], song_idx[val_idx], ratings[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "songmodel = MF_RS(len (uni_users), len(uni_songs), 11, reg_lambda=0.001, conf_lambda=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.485473169923488"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songmodel.evaluate(user_idx_val, song_idx_val, ratings_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0177569353469\n",
      "0.00728894162644\n",
      "0.00437736500334\n",
      "0.00299338117335\n",
      "0.00219362973096\n",
      "0.00167895445717\n",
      "0.0013241497355\n",
      "0.00106871611741\n",
      "0.000879055602825\n",
      "0.000735522116069\n",
      "0.000625660242455\n",
      "0.000540281646012\n",
      "0.000473986714263\n",
      "0.000421110533236\n",
      "0.000379479870317\n",
      "0.000346367369522\n",
      "0.000319600734569\n",
      "0.000298156250181\n",
      "0.000281122526503\n",
      "0.00026709278021\n",
      "0.000254938855913\n",
      "0.00024617767951\n",
      "0.000238400287955\n",
      "0.000231304382702\n",
      "0.000226440661354\n",
      "0.000221555254335\n",
      "0.000217854571005\n",
      "0.000214787934179\n",
      "0.000212105687271\n",
      "0.000209964586335\n",
      "0.000207458505785\n",
      "0.000206390633044\n",
      "0.000204533244047\n",
      "0.000203461896337\n",
      "0.000202069821913\n",
      "0.000201524780074\n",
      "0.000200898054696\n",
      "0.000199722880381\n",
      "0.000198729251046\n",
      "0.000198358584224\n",
      "0.000197979695542\n",
      "0.000198002902791\n",
      "0.000197466544545\n",
      "0.000196422465116\n",
      "0.000196156546823\n",
      "0.000196425579459\n",
      "0.000196051272447\n",
      "0.000195372224232\n",
      "0.000195045375614\n",
      "0.000194953288534\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "songmodel.train(user_idx, song_idx, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2804775435135487"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songmodel.evaluate(user_idx_val, song_idx_val, ratings_val)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
