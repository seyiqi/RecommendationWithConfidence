{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.2 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:53:06) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "print(sys.version)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MF_RS():\n",
    "    def __init__(self, numUsers, numSongs, embedding_dim, reg_lambda=0.01, conf_lambda=1.0, conf_dim = 1):\n",
    "        \n",
    "        #hyper parameters\n",
    "        self.batch_size = np.min([200, numUsers, numSongs]);\n",
    "        self.numUsers = numUsers\n",
    "        self.numSongs = numSongs\n",
    "        self.epochs = 50\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.conf_lambda = conf_lambda\n",
    "        \n",
    "        #embedding matricies for users and songs\n",
    "        self.userMat = tf.Variable(tf.random_normal([numUsers, embedding_dim]))\n",
    "        self.songMat = tf.Variable(tf.random_normal([numSongs, embedding_dim]))\n",
    "        self.userBias = tf.Variable(tf.random_normal([numUsers]))\n",
    "        self.songBias = tf.Variable(tf.random_normal([numSongs]))\n",
    "        self.overallBias = tf.Variable(tf.random_normal([1]))\n",
    "        self.C_user = tf.Variable(.1*tf.ones([numUsers, conf_dim]))\n",
    "        self.C_song = tf.Variable(.1*tf.ones([numSongs, conf_dim]))\n",
    "        \n",
    "        #input tensors for songs, usres, ratings\n",
    "        self.users = tf.placeholder(tf.int32, shape =(self.batch_size))\n",
    "        self.songs = tf.placeholder(tf.int32, shape =(self.batch_size))\n",
    "        self.rating = tf.placeholder(tf.float32, shape = (self.batch_size))\n",
    "        \n",
    "        #map each user/song to its feature vector\n",
    "        self.U = tf.nn.embedding_lookup(self.userMat, self.users)\n",
    "        self.W = tf.nn.embedding_lookup(self.songMat, self.songs)\n",
    "        # bias\n",
    "        self.U_bias = tf.nn.embedding_lookup(self.userBias, self.users)\n",
    "        self.W_bias = tf.nn.embedding_lookup(self.songBias, self.songs)\n",
    "        # confidence params\n",
    "        self.C_ui = tf.maximum(0.0, tf.nn.embedding_lookup(self.C_user, self.users))\n",
    "        self.C_sj = tf.maximum(0.0, tf.nn.embedding_lookup(self.C_song, self.songs))\n",
    "\n",
    "        \n",
    "        #predicted rating is dot product of user and song\n",
    "        bias = self.U_bias+self.W_bias+self.overallBias\n",
    "        pq = tf.reduce_sum(tf.mul(self.U, self.W), 1)\n",
    "        self.yhat = pq + bias\n",
    "            \n",
    "        # l2 reg\n",
    "        self.confidence_reg = self.conf_lambda * tf.reduce_sum(tf.exp(-self.C_ui) + tf.exp(-self.C_sj))\n",
    "        self.l2_reg = self.reg_lambda * ( tf.reduce_sum((tf.square(self.U) + tf.square(self.W))) + \n",
    "                                         tf.reduce_sum(tf.square(self.U_bias) + tf.square(self.W_bias)))\n",
    "        self.reg = self.confidence_reg + self.l2_reg\n",
    "        self.error = tf.reduce_mean(tf.reduce_sum(self.C_ui * self.C_sj, 1) * tf.nn.l2_loss(self.yhat - self.rating))\n",
    "        self.cost = (self.error + self.reg)/1e7\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate = .01).minimize(self.cost)\n",
    "        \n",
    "        self.session = tf.Session()\n",
    "        self.session.run(tf.initialize_all_variables())    \n",
    "        \n",
    "    def train(self, users, songs, ratings):\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            avg_cost = 0\n",
    "            perm = np.random.permutation(len(ratings))\n",
    "            num_batches = len(ratings) // self.batch_size\n",
    "            \n",
    "            for b_idx in range(num_batches):\n",
    "                \n",
    "                batch = perm[self.batch_size * b_idx:self.batch_size * (b_idx + 1)]\n",
    "                users_batch = users[batch]\n",
    "                songs_batch = songs[batch]\n",
    "                ratings_batch = ratings[batch]\n",
    "                                \n",
    "                avg_cost += self.session.run([self.cost, self.optimizer],\n",
    "                                  {self.users:users_batch, self.songs:songs_batch, self.rating:ratings_batch})[0]\n",
    "                \n",
    "            print(avg_cost/num_batches)\n",
    "    def test(self, users, songs):\n",
    "        yhat = np.zeros(len(users))\n",
    "        num_batches = len(users) // self.batch_size\n",
    "        for b_idx in range(num_batches):\n",
    "            batch = range(self.batch_size * b_idx,self.batch_size * (b_idx + 1))\n",
    "            users_batch = users[batch]\n",
    "            songs_batch = songs[batch]\n",
    "            yhat[batch] = self.session.run([self.yhat],\n",
    "                      {self.users:users_batch, self.songs:songs_batch})[0]\n",
    "        batch = range(-self.batch_size,0)\n",
    "        users_batch = users[batch]\n",
    "        songs_batch = songs[batch]\n",
    "        yhat[batch] = self.session.run([self.yhat],\n",
    "                      {self.users:users_batch, self.songs:songs_batch})[0]\n",
    "        return yhat\n",
    "    def evaluate(self, users, songs, ratings):\n",
    "        yhat = self.test(users, songs)\n",
    "        return np.mean((yhat - ratings)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.03209652025e-06\n",
      "1.03125591977e-06\n",
      "1.03020602182e-06\n",
      "1.02907449673e-06\n",
      "1.02793478618e-06\n",
      "1.02683520709e-06\n",
      "1.0258098655e-06\n",
      "1.02488138509e-06\n",
      "1.02406374936e-06\n",
      "1.02336423424e-06\n",
      "1.02278386294e-06\n",
      "1.0223186564e-06\n",
      "1.02196077023e-06\n",
      "1.02169906313e-06\n",
      "1.02151989267e-06\n",
      "1.02140791114e-06\n",
      "1.02134742974e-06\n",
      "1.02132310076e-06\n",
      "1.02131991753e-06\n",
      "1.02132469237e-06\n",
      "1.02132628399e-06\n",
      "1.02131571111e-06\n",
      "1.02128683466e-06\n",
      "1.02123522083e-06\n",
      "1.02115961909e-06\n",
      "1.02105980204e-06\n",
      "1.02093770238e-06\n",
      "1.02079661701e-06\n",
      "1.02064029761e-06\n",
      "1.02047295059e-06\n",
      "1.0202992371e-06\n",
      "1.0201230225e-06\n",
      "1.01994794477e-06\n",
      "1.01977673239e-06\n",
      "1.01961177279e-06\n",
      "1.01945443021e-06\n",
      "1.01930493202e-06\n",
      "1.01916316453e-06\n",
      "1.01902821825e-06\n",
      "1.01889918369e-06\n",
      "1.01877412817e-06\n",
      "1.01865157376e-06\n",
      "1.01852947409e-06\n",
      "1.01840691968e-06\n",
      "1.01828197785e-06\n",
      "1.01815408016e-06\n",
      "1.01802220343e-06\n",
      "1.01788612028e-06\n",
      "1.01774571704e-06\n",
      "1.01760122106e-06\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3, 4, 5])\n",
    "b = np.array([1, 2, 3, 4, 5])\n",
    "c = np.array([4, 3, 2, 5, 1])\n",
    "#unique users / songs\n",
    "uni_a = np.unique(a)\n",
    "uni_b = np.unique(b)\n",
    "\n",
    "#dict mapping the id to an index\n",
    "a_map = dict(zip(uni_a,range(len(uni_a))))\n",
    "b_map = dict(zip(uni_b,range(len(uni_b))))\n",
    "\n",
    "user_idx =  np.array([ a_map[user] for user in a])\n",
    "song_idx =  np.array([ b_map[song] for song in b])\n",
    "model = MF_RS(len(uni_a), len(uni_b), 7)\n",
    "np.random.seed(2)\n",
    "model.train(user_idx, song_idx, c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movieratings = pd.read_csv('ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getDfSummary(input_data):\n",
    "    output_data = input_data.describe(include = 'all').T\n",
    "    var = pd.DataFrame(data = {'nanvals': pd.Series(), 'number_distinct': pd.Series()})\n",
    "    for i in range(len(input_data.columns)):\n",
    "        nanvals = input_data.ix[:,i].isnull().sum()\n",
    "        number_distinct = len(input_data.ix[:,i].value_counts())\n",
    "        var = var.append(pd.DataFrame([[nanvals, number_distinct]], columns = ['nanvals', 'number_distinct']))\n",
    "    var.index = output_data.index.values\n",
    "    output_data['nanvals'] = var['nanvals']\n",
    "    output_data['number_distinct'] = var['number_distinct']\n",
    "    return output_data\n",
    "output_data = getDfSummary(movieratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671 9066\n"
     ]
    }
   ],
   "source": [
    "users = movieratings.ix[:,0].values\n",
    "songs = movieratings.ix[:,1].values\n",
    "ratings = movieratings.ix[:,2].values\n",
    "\n",
    "#unique users / songs\n",
    "uni_users = movieratings['userId'].unique()\n",
    "uni_songs = movieratings['movieId'].unique()\n",
    "\n",
    "#dict mapping the id to an index\n",
    "user_map = dict(zip(uni_users,range(len(uni_users))))\n",
    "song_map = dict(zip(uni_songs,range(len(uni_songs))))\n",
    "\n",
    "user_idx =  np.array([ user_map[user] for user in users])\n",
    "song_idx =  np.array([ song_map[song] for song in songs])\n",
    "\n",
    "print(len(uni_users),len(uni_songs))\n",
    "\n",
    "perm = np.random.permutation(len(users))\n",
    "trn_idx = perm[:(len(users)*2)//3]\n",
    "val_idx = perm[(len(users)*2)//3:]\n",
    "user_idx_trn, song_idx_trn, ratings_trn = user_idx[trn_idx], song_idx[trn_idx], ratings[trn_idx]\n",
    "user_idx_val, song_idx_val, ratings_val = user_idx[val_idx], song_idx[val_idx], ratings[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "songmodel = MF_RS(len (uni_users), len(uni_songs), 11, reg_lambda=0.001, conf_lambda=1000, conf_dim = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.636080223107992"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songmodel.evaluate(user_idx_val, song_idx_val, ratings_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0532136166245\n",
      "0.0218381272312\n",
      "0.013121736791\n",
      "0.00896964817308\n",
      "0.00656625431217\n",
      "0.00501724747056\n",
      "0.00395213423762\n",
      "0.003185456309\n",
      "0.00262003202317\n",
      "0.00219366226182\n",
      "0.00186793873995\n",
      "0.00161467132298\n",
      "0.00141773087834\n",
      "0.00126083238982\n",
      "0.00113771994179\n",
      "0.00103759308718\n",
      "0.000958210394252\n",
      "0.000896041884087\n",
      "0.000844651742722\n",
      "0.000802496855962\n",
      "0.000767920808517\n",
      "0.000739893552382\n",
      "0.000717573277885\n",
      "0.00069671014999\n",
      "0.000682119958801\n",
      "0.000667308451317\n",
      "0.000657778616529\n",
      "0.000648247414269\n",
      "0.000639579784009\n",
      "0.000632184081827\n",
      "0.000627973630035\n",
      "0.000621331769216\n",
      "0.000617766687414\n",
      "0.000613968412683\n",
      "0.000611095111177\n",
      "0.000607407675765\n",
      "0.000606091080117\n",
      "0.000603447377158\n",
      "0.000602204355178\n",
      "0.000601153037976\n",
      "0.00059729701106\n",
      "0.00059641037113\n",
      "0.000595267835015\n",
      "0.000594353262044\n",
      "0.000593454447458\n",
      "0.00059232681233\n",
      "0.000590962748567\n",
      "0.000590328781807\n",
      "0.000590229666035\n",
      "0.000589308253955\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "songmodel.train(user_idx, song_idx, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28559138800035"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songmodel.evaluate(user_idx_val, song_idx_val, ratings_val)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
