{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.9 (default, Jan  7 2015, 11:49:12) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.56)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "print(sys.version)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MF_RS():\n",
    "    def __init__(self, numUsers, numSongs, embedding_dim, reg_lambda=0.01):\n",
    "        \n",
    "        #hyper parameters\n",
    "        self.batch_size = 5;\n",
    "        self.numUsers = numUsers\n",
    "        self.numSongs = numSongs\n",
    "        self.epochs = 100\n",
    "        self.reg_lambda = reg_lambda\n",
    "        \n",
    "        #embedding matricies for users and songs\n",
    "        self.userMat = tf.Variable(tf.random_normal([numUsers, embedding_dim]))\n",
    "        self.songMat = tf.Variable(tf.random_normal([numSongs, embedding_dim]))\n",
    "        self.userBias = tf.Variable(tf.random_normal([numUsers]))\n",
    "        self.songBias = tf.Variable(tf.random_normal([numSongs]))\n",
    "        self.overallBias = tf.Variable(tf.random_normal([1]))\n",
    "        self.C_user = tf.Variable(tf.random_normal([numUsers]))\n",
    "        self.C_song = tf.Variable(tf.random_normal([numSongs]))\n",
    "        \n",
    "        #input tensors for songs, usres, ratings\n",
    "        self.users = tf.placeholder(tf.int32, shape =(self.batch_size))\n",
    "        self.songs = tf.placeholder(tf.int32, shape =(self.batch_size))\n",
    "        self.rating = tf.placeholder(tf.float32, shape = (self.batch_size))\n",
    "        \n",
    "        #map each user/song to its feature vector\n",
    "        self.U = tf.nn.embedding_lookup(self.userMat, self.users)\n",
    "        self.W = tf.nn.embedding_lookup(self.songMat, self.songs)\n",
    "        # bias\n",
    "        self.U_bias = tf.nn.embedding_lookup(self.userBias, self.users)\n",
    "        self.W_bias = tf.nn.embedding_lookup(self.songBias, self.songs)\n",
    "        # confidence params\n",
    "        self.C_ui = tf.nn.embedding_lookup(self.C_user, self.users)\n",
    "        self.C_sj = tf.nn.embedding_lookup(self.C_song, self.songs)\n",
    "        \n",
    "        #predicted rating is dot product of user and song\n",
    "        bias = self.U_bias+self.W_bias+self.overallBias\n",
    "        pq = tf.reduce_sum(tf.mul(self.U, self.W), 1)\n",
    "        self.yhat = pq + bias\n",
    "        \n",
    "        \n",
    "        # l2 reg\n",
    "        confidence_reg = tf.reduce_sum(tf.div(1e-10,self.C_ui) + tf.div(1e-10,self.C_sj))\n",
    "        self.l2_reg = self.reg_lambda * ( tf.reduce_sum((tf.square(self.U) + tf.square(self.W))) + \n",
    "                                         tf.reduce_sum(tf.square(self.U_bias) + tf.square(self.W_bias)) +\n",
    "                                        confidence_reg)\n",
    "        self.error = tf.reduce_mean(self.C_ui * self.C_sj * tf.nn.l2_loss(self.yhat - self.rating))\n",
    "        self.cost = self.error + self.l2_reg\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(learning_rate = .01).minimize(self.cost)\n",
    "        \n",
    "        self.session = tf.Session()\n",
    "        self.session.run(tf.initialize_all_variables())    \n",
    "        \n",
    "    def train(self, users, songs, ratings):\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            avg_cost = 0\n",
    "            perm = np.random.permutation(len(ratings))\n",
    "            num_batches = len(ratings) // self.batch_size\n",
    "            \n",
    "            for b_idx in range(num_batches):\n",
    "                \n",
    "                batch = perm[self.batch_size * b_idx:self.batch_size * (b_idx + 1)]\n",
    "                #if b_idx == num_batches - 1:\n",
    "                #    batch = perm[self.batch_size * b_idx:]\n",
    "                    \n",
    "                users_batch = users[batch]\n",
    "                songs_batch = songs[batch]\n",
    "                ratings_batch = ratings[batch]\n",
    "                                \n",
    "                avg_cost += self.session.run([self.cost, self.optimizer],\n",
    "                                  {self.users:users_batch, self.songs:songs_batch, self.rating:ratings_batch})[0]\n",
    "                \n",
    "            print(avg_cost/num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.1537027, None]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3, 4, 5])\n",
    "b = np.array([1, 2, 3, 4, 5])\n",
    "c = np.array([4, 3, 2, 5, 1])\n",
    "#unique users / songs\n",
    "uni_a = movieratings['userId'].unique()\n",
    "uni_b = movieratings['movieId'].unique()\n",
    "\n",
    "#dict mapping the id to an index\n",
    "a_map = dict(zip(uni_a,range(len(uni_a))))\n",
    "b_map = dict(zip(uni_b,range(len(uni_b))))\n",
    "\n",
    "user_idx =  np.array([ a_map[user] for user in users])\n",
    "song_idx =  np.array([ b_map[song] for song in songs])\n",
    "model = MF_RS(len(uni_a), len(uni_b), 7)\n",
    "print(model.session.run([model.cost, model.optimizer], {model.users:a, model.songs:b, model.rating:c}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movieratings = pd.read_csv('ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671\n",
      "9066\n"
     ]
    }
   ],
   "source": [
    "print(len(movieratings['userId'].unique()))\n",
    "print(len(movieratings['movieId'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   3.10000000e+01,   2.50000000e+00],\n",
       "       [  1.00000000e+00,   1.02900000e+03,   3.00000000e+00],\n",
       "       [  1.00000000e+00,   1.06100000e+03,   3.00000000e+00],\n",
       "       ..., \n",
       "       [  6.71000000e+02,   6.36500000e+03,   4.00000000e+00],\n",
       "       [  6.71000000e+02,   6.38500000e+03,   2.50000000e+00],\n",
       "       [  6.71000000e+02,   6.56500000e+03,   3.50000000e+00]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieratings.describe()\n",
    "movieratings[['userId', 'movieId','rating']].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getDfSummary(input_data):\n",
    "    output_data = input_data.describe(include = 'all').T\n",
    "    var = pd.DataFrame(data = {'nanvals': pd.Series(), 'number_distinct': pd.Series()})\n",
    "    for i in range(len(input_data.columns)):\n",
    "        nanvals = input_data.ix[:,i].isnull().sum()\n",
    "        number_distinct = len(input_data.ix[:,i].value_counts())\n",
    "        var = var.append(pd.DataFrame([[nanvals, number_distinct]], columns = ['nanvals', 'number_distinct']))\n",
    "    var.index = output_data.index.values\n",
    "    output_data['nanvals'] = var['nanvals']\n",
    "    output_data['number_distinct'] = var['number_distinct']\n",
    "    return output_data\n",
    "output_data = getDfSummary(movieratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>nanvals</th>\n",
       "      <th>number_distinct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <td>100004</td>\n",
       "      <td>3.470113e+02</td>\n",
       "      <td>1.951638e+02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>182</td>\n",
       "      <td>3.670000e+02</td>\n",
       "      <td>5.200000e+02</td>\n",
       "      <td>671</td>\n",
       "      <td>0</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <td>100004</td>\n",
       "      <td>1.254866e+04</td>\n",
       "      <td>2.636920e+04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1028</td>\n",
       "      <td>2.406500e+03</td>\n",
       "      <td>5.418000e+03</td>\n",
       "      <td>163949</td>\n",
       "      <td>0</td>\n",
       "      <td>9066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <td>100004</td>\n",
       "      <td>3.543608e+00</td>\n",
       "      <td>1.058064e+00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <td>100004</td>\n",
       "      <td>1.129639e+09</td>\n",
       "      <td>1.916858e+08</td>\n",
       "      <td>789652009.0</td>\n",
       "      <td>965847824</td>\n",
       "      <td>1.110422e+09</td>\n",
       "      <td>1.296192e+09</td>\n",
       "      <td>1476640644</td>\n",
       "      <td>0</td>\n",
       "      <td>78141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count          mean           std          min        25%  \\\n",
       "userId     100004  3.470113e+02  1.951638e+02          1.0        182   \n",
       "movieId    100004  1.254866e+04  2.636920e+04          1.0       1028   \n",
       "rating     100004  3.543608e+00  1.058064e+00          0.5          3   \n",
       "timestamp  100004  1.129639e+09  1.916858e+08  789652009.0  965847824   \n",
       "\n",
       "                    50%           75%         max  nanvals  number_distinct  \n",
       "userId     3.670000e+02  5.200000e+02         671        0              671  \n",
       "movieId    2.406500e+03  5.418000e+03      163949        0             9066  \n",
       "rating     4.000000e+00  4.000000e+00           5        0               10  \n",
       "timestamp  1.110422e+09  1.296192e+09  1476640644        0            78141  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'userId', u'movieId', u'rating', u'timestamp'], dtype='object')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieratings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(671, 9066)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "users = movieratings.ix[:,0].values\n",
    "songs = movieratings.ix[:,1].values\n",
    "ratings = movieratings.ix[:,2].values\n",
    "\n",
    "#unique users / songs\n",
    "uni_users = movieratings['userId'].unique()\n",
    "uni_songs = movieratings['movieId'].unique()\n",
    "\n",
    "#dict mapping the id to an index\n",
    "user_map = dict(zip(uni_users,range(len(uni_users))))\n",
    "song_map = dict(zip(uni_songs,range(len(uni_songs))))\n",
    "\n",
    "user_idx =  np.array([ user_map[user] for user in users])\n",
    "song_idx =  np.array([ song_map[song] for song in songs])\n",
    "\n",
    "print(len(uni_users),len(uni_songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "songmodel = MF_RS(671, 9066, 40, reg_lambda=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-56c0e1fbc5b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msongmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msong_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-119-5d6521af0eb2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, users, songs, ratings)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 avg_cost += self.session.run([self.cost, self.optimizer],\n\u001b[0;32m---> 72\u001b[0;31m                                   {self.users:users_batch, self.songs:songs_batch, self.rating:ratings_batch})[0]\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_cost\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 382\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    383\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0mmovers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 655\u001b[0;31m                            feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 723\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    728\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    710\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    711\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "songmodel.train(user_idx, song_idx, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(32)])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songmodel.songs.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2738.811"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# [ 2858  7190 57972  2105  2683] [ 4.5  4.   4.   3.5  3. ]\n",
    "a = np.array([606 ,547, 468, 654 ,304])\n",
    "b = np.array([ 2858,  7190, 57972,  2105 , 2683] )\n",
    "c = np.array([ 4.5 , 4.,   4.,   3.5,  3. ])\n",
    "\n",
    "songmodel.session.run([songmodel.cost, songmodel.optimizer],\n",
    "                                  {songmodel.users:600*np.ones(32), songmodel.songs:np.ones(32), songmodel.rating:np.ones(32)})[0]\n",
    "\n",
    "#model.session.run([model.yhat],\n",
    "#                                  {model.users:a, model.songs:b, model.rating:c})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tensorflow.python.ops.variables.Variable object at 0x10d621c10>, <tensorflow.python.ops.variables.Variable object at 0x111598790>, <tensorflow.python.ops.variables.Variable object at 0x111598d10>, <tensorflow.python.ops.variables.Variable object at 0x106c73e90>, <tensorflow.python.ops.variables.Variable object at 0x111652d90>, <tensorflow.python.ops.variables.Variable object at 0x106c9fad0>, <tensorflow.python.ops.variables.Variable object at 0x106c9f650>, <tensorflow.python.ops.variables.Variable object at 0x110fe1550>]\n"
     ]
    }
   ],
   "source": [
    "print(tf.all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   1,   1, ..., 671, 671, 671])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100004, 2)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([users,songs]).transpose().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
