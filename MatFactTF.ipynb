{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.2 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:53:06) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "print(sys.version)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MF_RS():\n",
    "    def __init__(self, numUsers, numSongs, embedding_dim, reg_lambda=0.01, conf_lambda=1.0, conf_dim = 1):\n",
    "        \n",
    "        #hyper parameters\n",
    "        self.batch_size = np.min([200, numUsers, numSongs]);\n",
    "        self.numUsers = numUsers\n",
    "        self.numSongs = numSongs\n",
    "        self.epochs = 50\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.conf_lambda = conf_lambda\n",
    "        \n",
    "        #embedding matricies for users and songs\n",
    "        self.userMat = tf.Variable(tf.random_normal([numUsers, embedding_dim]))\n",
    "        self.songMat = tf.Variable(tf.random_normal([numSongs, embedding_dim]))\n",
    "        self.userBias = tf.Variable(tf.random_normal([numUsers]))\n",
    "        self.songBias = tf.Variable(tf.random_normal([numSongs]))\n",
    "        self.overallBias = tf.Variable(tf.random_normal([1]))\n",
    "        self.C_user = tf.Variable(.1*tf.ones([numUsers, conf_dim]))\n",
    "        self.C_song = tf.Variable(.1*tf.ones([numSongs, conf_dim]))\n",
    "        \n",
    "        #input tensors for songs, usres, ratings\n",
    "        self.users = tf.placeholder(tf.int32, shape =(self.batch_size))\n",
    "        self.songs = tf.placeholder(tf.int32, shape =(self.batch_size))\n",
    "        self.rating = tf.placeholder(tf.float32, shape = (self.batch_size))\n",
    "        \n",
    "        #map each user/song to its feature vector\n",
    "        self.U = tf.nn.embedding_lookup(self.userMat, self.users)\n",
    "        self.W = tf.nn.embedding_lookup(self.songMat, self.songs)\n",
    "        # bias\n",
    "        self.U_bias = tf.nn.embedding_lookup(self.userBias, self.users)\n",
    "        self.W_bias = tf.nn.embedding_lookup(self.songBias, self.songs)\n",
    "        # confidence params\n",
    "        self.C_ui = tf.maximum(0.0, tf.nn.embedding_lookup(self.C_user, self.users))\n",
    "        self.C_sj = tf.maximum(0.0, tf.nn.embedding_lookup(self.C_song, self.songs))\n",
    "\n",
    "        \n",
    "        #predicted rating is dot product of user and song\n",
    "        bias = self.U_bias+self.W_bias+self.overallBias\n",
    "        pq = tf.reduce_sum(tf.mul(self.U, self.W), 1)\n",
    "        self.yhat = pq + bias\n",
    "            \n",
    "        # l2 reg\n",
    "        self.confidence_reg = self.conf_lambda * tf.reduce_sum(tf.exp(-self.C_ui) + tf.exp(-self.C_sj))\n",
    "        self.l2_reg = self.reg_lambda * ( tf.reduce_sum((tf.square(self.U) + tf.square(self.W))) + \n",
    "                                         tf.reduce_sum(tf.square(self.U_bias) + tf.square(self.W_bias)))\n",
    "        self.reg = self.l2_reg\n",
    "        self.error = tf.reduce_mean(tf.nn.l2_loss(self.yhat - self.rating))\n",
    "        self.cost = (self.error + self.reg)/1e7\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate = .01).minimize(self.cost)\n",
    "        \n",
    "        self.session = tf.Session()\n",
    "        self.session.run(tf.initialize_all_variables())    \n",
    "        \n",
    "    def train(self, users, songs, ratings, verb = 0):\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            avg_cost = 0\n",
    "            perm = np.random.permutation(len(ratings))\n",
    "            num_batches = len(ratings) // self.batch_size\n",
    "            \n",
    "            for b_idx in range(num_batches):\n",
    "                \n",
    "                batch = perm[self.batch_size * b_idx:self.batch_size * (b_idx + 1)]\n",
    "                users_batch = users[batch]\n",
    "                songs_batch = songs[batch]\n",
    "                ratings_batch = ratings[batch]\n",
    "                                \n",
    "                avg_cost += self.session.run([self.cost, self.optimizer],\n",
    "                                  {self.users:users_batch, self.songs:songs_batch, self.rating:ratings_batch})[0]\n",
    "            if verb > 0:\n",
    "                print(avg_cost/num_batches)\n",
    "    def test(self, users, songs):\n",
    "        yhat = np.zeros(len(users))\n",
    "        num_batches = len(users) // self.batch_size\n",
    "        for b_idx in range(num_batches):\n",
    "            batch = range(self.batch_size * b_idx,self.batch_size * (b_idx + 1))\n",
    "            users_batch = users[batch]\n",
    "            songs_batch = songs[batch]\n",
    "            yhat[batch] = self.session.run([self.yhat],\n",
    "                      {self.users:users_batch, self.songs:songs_batch})[0]\n",
    "        batch = range(-self.batch_size,0)\n",
    "        users_batch = users[batch]\n",
    "        songs_batch = songs[batch]\n",
    "        yhat[batch] = self.session.run([self.yhat],\n",
    "                      {self.users:users_batch, self.songs:songs_batch})[0]\n",
    "        return yhat\n",
    "    def evaluate(self, users, songs, ratings):\n",
    "        yhat = self.test(users, songs)\n",
    "        return np.mean((yhat - ratings)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MF_RS_C():\n",
    "    def __init__(self, numUsers, numSongs, embedding_dim, reg_lambda=0.01, conf_lambda=1.0, conf_dim = 1):\n",
    "        \n",
    "        #hyper parameters\n",
    "        self.batch_size = np.min([200, numUsers, numSongs]);\n",
    "        self.numUsers = numUsers\n",
    "        self.numSongs = numSongs\n",
    "        self.epochs = 50\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.conf_lambda = conf_lambda\n",
    "        \n",
    "        #embedding matricies for users and songs\n",
    "        self.userMat = tf.Variable(tf.random_normal([numUsers, embedding_dim]))\n",
    "        self.songMat = tf.Variable(tf.random_normal([numSongs, embedding_dim]))\n",
    "        self.userBias = tf.Variable(tf.random_normal([numUsers]))\n",
    "        self.songBias = tf.Variable(tf.random_normal([numSongs]))\n",
    "        self.overallBias = tf.Variable(tf.random_normal([1]))\n",
    "        self.C_user = tf.Variable(.1*tf.ones([numUsers, conf_dim]))\n",
    "        self.C_song = tf.Variable(.1*tf.ones([numSongs, conf_dim]))\n",
    "        \n",
    "        #input tensors for songs, usres, ratings\n",
    "        self.users = tf.placeholder(tf.int32, shape =(self.batch_size))\n",
    "        self.songs = tf.placeholder(tf.int32, shape =(self.batch_size))\n",
    "        self.rating = tf.placeholder(tf.float32, shape = (self.batch_size))\n",
    "        \n",
    "        #map each user/song to its feature vector\n",
    "        self.U = tf.nn.embedding_lookup(self.userMat, self.users)\n",
    "        self.W = tf.nn.embedding_lookup(self.songMat, self.songs)\n",
    "        # bias\n",
    "        self.U_bias = tf.nn.embedding_lookup(self.userBias, self.users)\n",
    "        self.W_bias = tf.nn.embedding_lookup(self.songBias, self.songs)\n",
    "        # confidence params\n",
    "        self.C_ui = tf.maximum(0.0, tf.nn.embedding_lookup(self.C_user, self.users))\n",
    "        self.C_sj = tf.maximum(0.0, tf.nn.embedding_lookup(self.C_song, self.songs))\n",
    "\n",
    "        \n",
    "        #predicted rating is dot product of user and song\n",
    "        bias = self.U_bias+self.W_bias+self.overallBias\n",
    "        pq = tf.reduce_sum(tf.mul(self.U, self.W), 1)\n",
    "        self.yhat = pq + bias\n",
    "            \n",
    "        # l2 reg\n",
    "        self.confidence_reg = self.conf_lambda * tf.reduce_sum(tf.exp(-self.C_ui) + tf.exp(-self.C_sj))\n",
    "        self.l2_reg = self.reg_lambda * ( tf.reduce_sum((tf.square(self.U) + tf.square(self.W))) + \n",
    "                                         tf.reduce_sum(tf.square(self.U_bias) + tf.square(self.W_bias)))\n",
    "        self.reg = self.confidence_reg + self.l2_reg\n",
    "        self.error = tf.reduce_mean(tf.reduce_sum(self.C_ui * self.C_sj, 1) * tf.nn.l2_loss(self.yhat - self.rating))\n",
    "        self.cost = (self.error + self.reg)/1e7\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate = .01).minimize(self.cost)\n",
    "        \n",
    "        self.session = tf.Session()\n",
    "        self.session.run(tf.initialize_all_variables())    \n",
    "        \n",
    "    def train(self, users, songs, ratings, verb = 0):\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            avg_cost = 0\n",
    "            perm = np.random.permutation(len(ratings))\n",
    "            num_batches = len(ratings) // self.batch_size\n",
    "            \n",
    "            for b_idx in range(num_batches):\n",
    "                \n",
    "                batch = perm[self.batch_size * b_idx:self.batch_size * (b_idx + 1)]\n",
    "                users_batch = users[batch]\n",
    "                songs_batch = songs[batch]\n",
    "                ratings_batch = ratings[batch]\n",
    "                                \n",
    "                avg_cost += self.session.run([self.cost, self.optimizer],\n",
    "                                  {self.users:users_batch, self.songs:songs_batch, self.rating:ratings_batch})[0]\n",
    "            if verb > 0:\n",
    "                print(avg_cost/num_batches)\n",
    "    def test(self, users, songs):\n",
    "        yhat = np.zeros(len(users))\n",
    "        num_batches = len(users) // self.batch_size\n",
    "        for b_idx in range(num_batches):\n",
    "            batch = range(self.batch_size * b_idx,self.batch_size * (b_idx + 1))\n",
    "            users_batch = users[batch]\n",
    "            songs_batch = songs[batch]\n",
    "            yhat[batch] = self.session.run([self.yhat],\n",
    "                      {self.users:users_batch, self.songs:songs_batch})[0]\n",
    "        batch = range(-self.batch_size,0)\n",
    "        users_batch = users[batch]\n",
    "        songs_batch = songs[batch]\n",
    "        yhat[batch] = self.session.run([self.yhat],\n",
    "                      {self.users:users_batch, self.songs:songs_batch})[0]\n",
    "        return yhat\n",
    "    def evaluate(self, users, songs, ratings):\n",
    "        yhat = self.test(users, songs)\n",
    "        return np.mean((yhat - ratings)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3, 4, 5])\n",
    "b = np.array([1, 2, 3, 4, 5])\n",
    "c = np.array([4, 3, 2, 5, 1])\n",
    "#unique users / songs\n",
    "uni_a = np.unique(a)\n",
    "uni_b = np.unique(b)\n",
    "\n",
    "#dict mapping the id to an index\n",
    "a_map = dict(zip(uni_a,range(len(uni_a))))\n",
    "b_map = dict(zip(uni_b,range(len(uni_b))))\n",
    "\n",
    "user_idx =  np.array([ a_map[user] for user in a])\n",
    "song_idx =  np.array([ b_map[song] for song in b])\n",
    "model = MF_RS_C(len(uni_a), len(uni_b), 7)\n",
    "np.random.seed(2)\n",
    "model.train(user_idx, song_idx, c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movieratings = pd.read_csv('ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getDfSummary(input_data):\n",
    "    output_data = input_data.describe(include = 'all').T\n",
    "    var = pd.DataFrame(data = {'nanvals': pd.Series(), 'number_distinct': pd.Series()})\n",
    "    for i in range(len(input_data.columns)):\n",
    "        nanvals = input_data.ix[:,i].isnull().sum()\n",
    "        number_distinct = len(input_data.ix[:,i].value_counts())\n",
    "        var = var.append(pd.DataFrame([[nanvals, number_distinct]], columns = ['nanvals', 'number_distinct']))\n",
    "    var.index = output_data.index.values\n",
    "    output_data['nanvals'] = var['nanvals']\n",
    "    output_data['number_distinct'] = var['number_distinct']\n",
    "    return output_data\n",
    "output_data = getDfSummary(movieratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671 9066\n"
     ]
    }
   ],
   "source": [
    "users = movieratings.ix[:,0].values\n",
    "songs = movieratings.ix[:,1].values\n",
    "ratings = movieratings.ix[:,2].values\n",
    "\n",
    "#unique users / songs\n",
    "uni_users = movieratings['userId'].unique()\n",
    "uni_songs = movieratings['movieId'].unique()\n",
    "\n",
    "#dict mapping the id to an index\n",
    "user_map = dict(zip(uni_users,range(len(uni_users))))\n",
    "song_map = dict(zip(uni_songs,range(len(uni_songs))))\n",
    "\n",
    "user_idx =  np.array([ user_map[user] for user in users])\n",
    "song_idx =  np.array([ song_map[song] for song in songs])\n",
    "\n",
    "print(len(uni_users),len(uni_songs))\n",
    "\n",
    "perm = np.random.permutation(len(users))\n",
    "trn_idx = perm[:(len(users)*2)//3]\n",
    "val_idx = perm[(len(users)*2)//3:]\n",
    "user_idx_trn, song_idx_trn, ratings_trn = user_idx[trn_idx], song_idx[trn_idx], ratings[trn_idx]\n",
    "user_idx_val, song_idx_val, ratings_val = user_idx[val_idx], song_idx[val_idx], ratings[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "songmodel = MF_RS_C(len (uni_users), len(uni_songs), 30, reg_lambda=0.001, conf_lambda=1000, conf_dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.856081304857362"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songmodel.evaluate(user_idx_val, song_idx_val, ratings_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "songmodel.train(user_idx, song_idx, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19056920539983116"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songmodel.evaluate(user_idx_val, song_idx_val, ratings_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy before training 50.8160074307\n",
      "accuracy after training 1.48320463256\n"
     ]
    }
   ],
   "source": [
    "songmodel = MF_RS_C(len (uni_users), len(uni_songs), 30, reg_lambda=0.001, conf_lambda=1000, conf_dim = 3)\n",
    "print(\"accuracy before training\", songmodel.evaluate(user_idx_val, song_idx_val, ratings_val))\n",
    "np.random.seed(1)\n",
    "songmodel.train(user_idx_trn, song_idx_trn, ratings_trn)\n",
    "print(\"accuracy after training\", songmodel.evaluate(user_idx_val, song_idx_val, ratings_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy before training 22.5522324473\n",
      "accuracy after training with edim  10  and confidence dim  1 :  1.70559771039\n",
      "accuracy before training 27.3631900114\n",
      "accuracy after training with edim  10  and confidence dim  2 :  1.67216269966\n",
      "accuracy before training 42.110852886\n",
      "accuracy after training with edim  30  and confidence dim  1 :  1.52946395456\n",
      "accuracy before training 45.5942543267\n",
      "accuracy after training with edim  30  and confidence dim  2 :  1.45924576727\n",
      "accuracy before training 66.6670639318\n",
      "accuracy after training with edim  50  and confidence dim  1 :  1.30741824115\n",
      "accuracy before training 65.1900490696\n",
      "accuracy after training with edim  50  and confidence dim  2 :  1.28563959477\n"
     ]
    }
   ],
   "source": [
    "for edim in [10, 30, 50]:\n",
    "    for d in [1, 2]:\n",
    "        songmodel = MF_RS_C(len (uni_users), len(uni_songs), edim, reg_lambda=0.001, conf_lambda=1000, conf_dim = d)\n",
    "        print(\"accuracy before training\", songmodel.evaluate(user_idx_val, song_idx_val, ratings_val))\n",
    "        np.random.seed(1)\n",
    "        songmodel.train(user_idx_trn, song_idx_trn, ratings_trn)\n",
    "        print(\"accuracy after training with edim \", edim, \" and confidence dim \", d, \": \", songmodel.evaluate(user_idx_val, song_idx_val, ratings_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy before training 25.3572524922\n",
      "accuracy after training with edim  10  and no confidence:  1.68825014247\n",
      "accuracy before training 50.1544582794\n",
      "accuracy after training with edim  30  and no confidence:  2.86766386256\n",
      "accuracy before training 65.6689009167\n",
      "accuracy after training with edim  50  and no confidence:  3.37460484837\n"
     ]
    }
   ],
   "source": [
    "for edim in [10, 30, 50]:\n",
    "    for d in [1]:\n",
    "        songmodel = MF_RS(len (uni_users), len(uni_songs), edim, reg_lambda=0.001, conf_lambda=1000, conf_dim = d)\n",
    "        print(\"accuracy before training\", songmodel.evaluate(user_idx_val, song_idx_val, ratings_val))\n",
    "        np.random.seed(1)\n",
    "        songmodel.train(user_idx_trn, song_idx_trn, ratings_trn)\n",
    "        print(\"accuracy after training with edim \", edim, \" and no confidence: \", songmodel.evaluate(user_idx_val, song_idx_val, ratings_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
